{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install praw -q\n",
    "import praw\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('/home/jovyan/reddit/', 'env.json')) as secrets_file:\n",
    "    secrets = json.load(secrets_file)\n",
    "    \n",
    "def get_secret(setting, secrets=secrets):\n",
    "    \"\"\"Get secret setting or fail with ImproperlyConfigured\"\"\"\n",
    "    try:\n",
    "        return secrets[setting]\n",
    "    except KeyError:\n",
    "        raise ImproperlyConfigured(\"Set the {} setting\".format(setting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_read_only = praw.Reddit(client_id=get_secret('client_id'),       # your client id\n",
    "                               client_secret=get_secret('client_secret'),     # your client secret\n",
    "                               user_agent=get_secret('user_agent'))     # your user agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = reddit_read_only.subreddit(\"battlestations\")\n",
    "\n",
    "posts = subreddit.top(\"year\")\n",
    " \n",
    "posts_dict = {\"Title\": [],\n",
    "              \"ID\": [], \"Upvotes\": [],\n",
    "              \"Total Comments\": [], \"Post URL\": []\n",
    "              }\n",
    " \n",
    "for post in posts:\n",
    "    # Title of each post\n",
    "    posts_dict[\"Title\"].append(post.title)\n",
    "     \n",
    "    # Unique ID of each post\n",
    "    posts_dict[\"ID\"].append(post.id)\n",
    "     \n",
    "    # The score of a post\n",
    "    posts_dict[\"Upvotes\"].append(post.score)\n",
    "     \n",
    "    # Total number of comments inside the post\n",
    "    posts_dict[\"Total Comments\"].append(post.num_comments)\n",
    "     \n",
    "    # URL of each post\n",
    "    posts_dict[\"Post URL\"].append(post.url)\n",
    " \n",
    "# Saving the data in a pandas dataframe\n",
    "top_posts = pd.DataFrame(posts_dict)\n",
    "top_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "new_dir = \"pics-\" + datetime.now().strftime(\"%m%d%Y%H%M%S\")\n",
    "final_directory = os.path.join(current_directory, new_dir)\n",
    "if not os.path.exists(final_directory):\n",
    "   os.makedirs(final_directory)\n",
    "\n",
    "for index, row in top_posts.iterrows():\n",
    "    url =  row['Post URL']\n",
    "    filename = row['ID']\n",
    "    \n",
    "    res = requests.get(url, stream = True)\n",
    "    if res.status_code == 200:\n",
    "        with open(final_directory + '/' + filename + '.jpg','wb') as f:\n",
    "            shutil.copyfileobj(res.raw, f)\n",
    "    else:\n",
    "        print(filename + ' couldn\\'t be retrieved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 162792 submissions through 2009-12-09\n",
      "Saved 162792 submissions\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "username = \"\"  # put the username you want to download in the quotes\n",
    "subreddit = \"battlestations\"  # put the subreddit you want to download in the quotes\n",
    "# leave either one blank to download an entire user's or subreddit's history\n",
    "# or fill in both to download a specific users history from a specific subreddit\n",
    "\n",
    "filter_string = None\n",
    "if username == \"\" and subreddit == \"\":\n",
    "    print(\"Fill in either username or subreddit\")\n",
    "    sys.exit(0)\n",
    "elif username == \"\" and subreddit != \"\":\n",
    "    filter_string = f\"subreddit={subreddit}\"\n",
    "elif username != \"\" and subreddit == \"\":\n",
    "    filter_string = f\"author={username}\"\n",
    "else:\n",
    "    filter_string = f\"author={username}&subreddit={subreddit}\"\n",
    "\n",
    "url = \"https://api.pushshift.io/reddit/{}/search?limit=1000&sort=desc&{}&before=\"\n",
    "\n",
    "start_time = datetime.utcnow()\n",
    "\n",
    "posts_dict = {\"Title\": [],\n",
    "              \"ID\": [], \"Date\": [], \"Upvotes\": [], \"URL\": []\n",
    "              }\n",
    "posts = pd.DataFrame(posts_dict)\n",
    "\n",
    "\n",
    "\n",
    "filename = 'data-' + datetime.now().strftime(\"%m%d%Y%H%M%S\") + '.csv'\n",
    "object_type = \"submission\"\n",
    "print(f\"Saving {object_type}s to {filename}\")\n",
    "\n",
    "count = 0\n",
    "previous_epoch = int(start_time.timestamp())\n",
    "while True:\n",
    "    new_url = url.format(object_type, filter_string)+str(previous_epoch)\n",
    "    json_text = requests.get(new_url, headers={'User-Agent': \"Post downloader by /u/Watchful1\"})\n",
    "    time.sleep(1)  # pushshift has a rate limit, if we send requests too fast it will start returning error messages\n",
    "    try:\n",
    "        json_data = json_text.json()\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        time.sleep(1)\n",
    "        continue\n",
    "\n",
    "    if 'data' not in json_data:\n",
    "        break\n",
    "    objects = json_data['data']\n",
    "    if len(objects) == 0:\n",
    "        break\n",
    "\n",
    "    batch_dict = {\"Title\": [],\n",
    "          \"ID\": [], \"Date\": [], \"Upvotes\": [], \"URL\": []\n",
    "          }    \n",
    "\n",
    "    for object in objects:\n",
    "        previous_epoch = object['created_utc'] - 1\n",
    "        count += 1\n",
    "        if object_type == 'submission':\n",
    "            if 'url' not in object:\n",
    "                print(\"continuing\")\n",
    "                continue\n",
    "            try:\n",
    "                batch_dict[\"Title\"].append(object['title'])\n",
    "                batch_dict[\"ID\"].append(object['id'])\n",
    "                batch_dict[\"Date\"].append(datetime.fromtimestamp(object['created_utc']).strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "                batch_dict[\"Upvotes\"].append(object['score'])\n",
    "                batch_dict[\"URL\"].append(object['url'])\n",
    "\n",
    "                # handle.write(\"Title: \" + str(object['title']))\n",
    "                # handle.write(\"\\nID: \" + str(object['id']))\n",
    "                # handle.write(\"\\nScore: \" + str(object['score']))\n",
    "                # handle.write(\"\\nAwards: \" + str(object['total_awards_received']))\n",
    "                # handle.write(\"\\nTime: \" + datetime.fromtimestamp(object['created_utc']).strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "                # handle.write(\"\\nURL: \" + str(object['url']))\n",
    "                # handle.write(\"\\n-------------------------------\\n\")\n",
    "            except Exception as err:\n",
    "                print(f\"Couldn't print post: {object['url']}\")\n",
    "                print(traceback.format_exc())\n",
    "\n",
    "    batch = pd.DataFrame(batch_dict)\n",
    "    posts = posts.append(batch)\n",
    "    posts.to_csv(filename, index=False)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    print(\"Saved {} {}s through {}\".format(count, object_type, datetime.fromtimestamp(previous_epoch).strftime(\"%Y-%m-%d\")))\n",
    "\n",
    "print(f\"Saved {count} {object_type}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Upvotes</th>\n",
       "      <th>URL</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Gum Ball PC. Tried to be different and fun...</td>\n",
       "      <td>88mrjw</td>\n",
       "      <td>2018-03-31 23:53:50</td>\n",
       "      <td>34077</td>\n",
       "      <td>https://i.redd.it/qxw0cetfs6p01.jpg</td>\n",
       "      <td>Downloaded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I live in a van and this is my battle station!</td>\n",
       "      <td>cetna0</td>\n",
       "      <td>2019-07-18 15:05:17</td>\n",
       "      <td>32530</td>\n",
       "      <td>https://i.redd.it/5bh2vhihu2b31.jpg</td>\n",
       "      <td>Downloaded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I call it...Serenity</td>\n",
       "      <td>bx4csz</td>\n",
       "      <td>2019-06-05 16:10:59</td>\n",
       "      <td>31412</td>\n",
       "      <td>https://i.redd.it/oy36njp1bk231.jpg</td>\n",
       "      <td>Downloaded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My Music / Gaming Room</td>\n",
       "      <td>85ikwj</td>\n",
       "      <td>2018-03-19 10:53:54</td>\n",
       "      <td>27462</td>\n",
       "      <td>https://i.redd.it/kj4rw6mqapm01.jpg</td>\n",
       "      <td>Downloaded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Confined to bed after surgury - built this in ...</td>\n",
       "      <td>8pkdt1</td>\n",
       "      <td>2018-06-08 14:37:20</td>\n",
       "      <td>23885</td>\n",
       "      <td>https://i.redd.it/lrp3ezjags211.jpg</td>\n",
       "      <td>Downloaded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95615</th>\n",
       "      <td>Different vibe of my set up</td>\n",
       "      <td>d9ugxm</td>\n",
       "      <td>2019-09-27 03:07:27</td>\n",
       "      <td>0</td>\n",
       "      <td>https://i.redd.it/lx1yr66bz1p31.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95616</th>\n",
       "      <td>Blendtec Total Classic Original Blender - Wild...</td>\n",
       "      <td>d9k0ll</td>\n",
       "      <td>2019-09-26 13:59:38</td>\n",
       "      <td>0</td>\n",
       "      <td>https://i.redd.it/6b5dn1jo2yo31.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95617</th>\n",
       "      <td>My battlestation with rgb and philips hue.</td>\n",
       "      <td>d9kudu</td>\n",
       "      <td>2019-09-26 15:03:29</td>\n",
       "      <td>0</td>\n",
       "      <td>https://i.redd.it/z8hvcic5eyo31.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95618</th>\n",
       "      <td>Living on campus in the year 2019...</td>\n",
       "      <td>d9lua5</td>\n",
       "      <td>2019-09-26 16:16:12</td>\n",
       "      <td>0</td>\n",
       "      <td>https://i.redd.it/f5pfhqf4ryo31.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95619</th>\n",
       "      <td>The command station</td>\n",
       "      <td>8yw8bj</td>\n",
       "      <td>2018-07-14 20:33:13</td>\n",
       "      <td>0</td>\n",
       "      <td>https://i.redd.it/ij064mus4z911.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95620 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Title      ID  \\\n",
       "0      The Gum Ball PC. Tried to be different and fun...  88mrjw   \n",
       "1         I live in a van and this is my battle station!  cetna0   \n",
       "2                                   I call it...Serenity  bx4csz   \n",
       "3                                 My Music / Gaming Room  85ikwj   \n",
       "4      Confined to bed after surgury - built this in ...  8pkdt1   \n",
       "...                                                  ...     ...   \n",
       "95615                        Different vibe of my set up  d9ugxm   \n",
       "95616  Blendtec Total Classic Original Blender - Wild...  d9k0ll   \n",
       "95617         My battlestation with rgb and philips hue.  d9kudu   \n",
       "95618               Living on campus in the year 2019...  d9lua5   \n",
       "95619                                The command station  8yw8bj   \n",
       "\n",
       "                      Date  Upvotes                                  URL  \\\n",
       "0      2018-03-31 23:53:50    34077  https://i.redd.it/qxw0cetfs6p01.jpg   \n",
       "1      2019-07-18 15:05:17    32530  https://i.redd.it/5bh2vhihu2b31.jpg   \n",
       "2      2019-06-05 16:10:59    31412  https://i.redd.it/oy36njp1bk231.jpg   \n",
       "3      2018-03-19 10:53:54    27462  https://i.redd.it/kj4rw6mqapm01.jpg   \n",
       "4      2018-06-08 14:37:20    23885  https://i.redd.it/lrp3ezjags211.jpg   \n",
       "...                    ...      ...                                  ...   \n",
       "95615  2019-09-27 03:07:27        0  https://i.redd.it/lx1yr66bz1p31.jpg   \n",
       "95616  2019-09-26 13:59:38        0  https://i.redd.it/6b5dn1jo2yo31.jpg   \n",
       "95617  2019-09-26 15:03:29        0  https://i.redd.it/z8hvcic5eyo31.jpg   \n",
       "95618  2019-09-26 16:16:12        0  https://i.redd.it/f5pfhqf4ryo31.jpg   \n",
       "95619  2018-07-14 20:33:13        0  https://i.redd.it/ij064mus4z911.jpg   \n",
       "\n",
       "           Status  \n",
       "0      Downloaded  \n",
       "1      Downloaded  \n",
       "2      Downloaded  \n",
       "3      Downloaded  \n",
       "4      Downloaded  \n",
       "...           ...  \n",
       "95615         NaN  \n",
       "95616         NaN  \n",
       "95617         NaN  \n",
       "95618         NaN  \n",
       "95619         NaN  \n",
       "\n",
       "[95620 rows x 6 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = pd.read_csv('posts.csv', dtype={'Title': 'str',\n",
    "                                        'ID': 'str',\n",
    "                                        'Date': 'str',\n",
    "                                        'Upvotes': 'int',\n",
    "                                        'URL': 'str',\n",
    "                                        'Status': 'str'\n",
    "                                       })\n",
    "posts = posts.iloc[: , 1:]\n",
    "#posts = posts.sort_values(by=['Upvotes'], ascending=False)\n",
    "#header_list = [\"Title\", \"ID\", \"Date\", \"Upvotes\", \"URL\", \"Status\"]\n",
    "#posts = posts.reindex(columns = header_list)\n",
    "posts = posts[posts['URL'].str.contains(\"https://i.redd.it/\")]\n",
    "posts = posts.reset_index(drop=True)\n",
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Upvotes</th>\n",
       "      <th>URL</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can I join your ranks?</td>\n",
       "      <td>7y1byy</td>\n",
       "      <td>2018-02-16 19:42:51</td>\n",
       "      <td>29146</td>\n",
       "      <td>https://i.imgur.com/WFXtOln.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Update: My Brooklyn Battlestation</td>\n",
       "      <td>b1s9fi</td>\n",
       "      <td>2019-03-16 13:09:06</td>\n",
       "      <td>23215</td>\n",
       "      <td>https://i.imgur.com/SekRb37.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Last LAN before I'm a Dad!</td>\n",
       "      <td>nyycak</td>\n",
       "      <td>2021-06-13 15:09:40</td>\n",
       "      <td>22052</td>\n",
       "      <td>https://i.imgur.com/wGoGyJe.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pretty happy with how this turned out</td>\n",
       "      <td>6jieb8</td>\n",
       "      <td>2017-06-26 02:21:13</td>\n",
       "      <td>16249</td>\n",
       "      <td>http://i.imgur.com/pQz53qW.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ultrawides in an Old Cotton Mill</td>\n",
       "      <td>6iwlqy</td>\n",
       "      <td>2017-06-22 21:18:59</td>\n",
       "      <td>12452</td>\n",
       "      <td>http://i.imgur.com/7N5NVE4.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16290</th>\n",
       "      <td>It gets the job done</td>\n",
       "      <td>53096b</td>\n",
       "      <td>2016-09-16 04:22:04</td>\n",
       "      <td>0</td>\n",
       "      <td>http://i.imgur.com/ZMOgDEu.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16291</th>\n",
       "      <td>Server, Mac, BSD, other Mac, and Win gaming rig</td>\n",
       "      <td>52fu4t</td>\n",
       "      <td>2016-09-12 18:27:56</td>\n",
       "      <td>0</td>\n",
       "      <td>http://i.imgur.com/abIGMOy.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16292</th>\n",
       "      <td>Temp Command Center</td>\n",
       "      <td>52fvs3</td>\n",
       "      <td>2016-09-12 18:35:54</td>\n",
       "      <td>0</td>\n",
       "      <td>http://i.imgur.com/1p83ckh.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16293</th>\n",
       "      <td>My Battlestation!</td>\n",
       "      <td>12p91b</td>\n",
       "      <td>2012-11-06 01:07:54</td>\n",
       "      <td>0</td>\n",
       "      <td>http://i.imgur.com/tTDtV.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16294</th>\n",
       "      <td>STOP in the name of my station</td>\n",
       "      <td>12mi6f</td>\n",
       "      <td>2012-11-04 19:36:50</td>\n",
       "      <td>0</td>\n",
       "      <td>http://i.imgur.com/ZdX7K.jpg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16295 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title      ID  \\\n",
       "0                               Can I join your ranks?  7y1byy   \n",
       "1                    Update: My Brooklyn Battlestation  b1s9fi   \n",
       "2                           Last LAN before I'm a Dad!  nyycak   \n",
       "3                Pretty happy with how this turned out  6jieb8   \n",
       "4                     Ultrawides in an Old Cotton Mill  6iwlqy   \n",
       "...                                                ...     ...   \n",
       "16290                             It gets the job done  53096b   \n",
       "16291  Server, Mac, BSD, other Mac, and Win gaming rig  52fu4t   \n",
       "16292                              Temp Command Center  52fvs3   \n",
       "16293                                My Battlestation!  12p91b   \n",
       "16294                   STOP in the name of my station  12mi6f   \n",
       "\n",
       "                      Date  Upvotes                              URL  Status  \n",
       "0      2018-02-16 19:42:51    29146  https://i.imgur.com/WFXtOln.jpg     NaN  \n",
       "1      2019-03-16 13:09:06    23215  https://i.imgur.com/SekRb37.jpg     NaN  \n",
       "2      2021-06-13 15:09:40    22052  https://i.imgur.com/wGoGyJe.jpg     NaN  \n",
       "3      2017-06-26 02:21:13    16249   http://i.imgur.com/pQz53qW.jpg     NaN  \n",
       "4      2017-06-22 21:18:59    12452   http://i.imgur.com/7N5NVE4.jpg     NaN  \n",
       "...                    ...      ...                              ...     ...  \n",
       "16290  2016-09-16 04:22:04        0   http://i.imgur.com/ZMOgDEu.jpg     NaN  \n",
       "16291  2016-09-12 18:27:56        0   http://i.imgur.com/abIGMOy.jpg     NaN  \n",
       "16292  2016-09-12 18:35:54        0   http://i.imgur.com/1p83ckh.jpg     NaN  \n",
       "16293  2012-11-06 01:07:54        0     http://i.imgur.com/tTDtV.jpg     NaN  \n",
       "16294  2012-11-04 19:36:50        0     http://i.imgur.com/ZdX7K.jpg     NaN  \n",
       "\n",
       "[16295 rows x 6 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "posts2 = pd.read_csv('data-01292022191230.csv', dtype={'Title': 'str',\n",
    "                                        'ID': 'str',\n",
    "                                        'Date': 'str',\n",
    "                                        'Upvotes': 'int',\n",
    "                                        'URL': 'str'\n",
    "                                       })\n",
    "# posts2 = posts.iloc[: , 1:]\n",
    "posts2 = posts2.sort_values(by=['Upvotes'], ascending=False)\n",
    "header_list = [\"Title\", \"ID\", \"Date\", \"Upvotes\", \"URL\", \"Status\"]\n",
    "posts2 = posts2.reindex(columns = header_list)\n",
    "posts2 = posts2[posts2['URL'].str.contains(\"i.imgur.com\")]\n",
    "posts2 = posts2.reset_index(drop=True)\n",
    "posts2\n",
    "\n",
    "# http*://imgur.com domains = 39445\n",
    "# http*://i.imgur.com domains = 16295\n",
    "# total = 55740"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped c822t9 (3108)\n"
     ]
    }
   ],
   "source": [
    "!pip install wget -q\n",
    "import wget\n",
    "import time\n",
    "import traceback\n",
    "import sys\n",
    "from os.path import exists\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "new_dir = \"pics\" # -\" + datetime.now().strftime(\"%m%d%Y%H%M%S\")\n",
    "final_directory = os.path.join(current_directory, new_dir)\n",
    "if not os.path.exists(final_directory):\n",
    "   os.makedirs(final_directory)\n",
    "\n",
    "processed = 0\n",
    "skipped = 0\n",
    "failed = 0\n",
    "success = 0\n",
    "\n",
    "for index, row in posts.iterrows():\n",
    "    \n",
    "    # check if the file exists already\n",
    "    if exists(final_directory + '/' + filename + '.jpg'):\n",
    "        success += 1\n",
    "        processed += 1\n",
    "        posts.at[index,'Status'] = \"Downloaded\"\n",
    "        clear_output(wait=True)\n",
    "        print(\"Skipped \" + row['ID'] + \" (\" + str(processed) + \")\")\n",
    "        time.sleep(0.05)\n",
    "        continue\n",
    "        \n",
    "    # check if previously failed\n",
    "    if row['Status'] == \"Failed\":\n",
    "        failed += 1\n",
    "        processed += 1\n",
    "        continue\n",
    "        \n",
    "    try:\n",
    "        wget.download(url, current_directory + '/test.jpg')\n",
    "        success += 1\n",
    "        posts.at[index,'Status'] = \"Downloaded\"\n",
    "    except:\n",
    "        failed += 1\n",
    "        posts.at[index,'Status'] = \"Failed\"\n",
    "        \n",
    "    processed += 1\n",
    "    clear_output(wait=True)\n",
    "    total = 162792\n",
    "    percentage = (processed / total) * 100\n",
    "    \n",
    "    if (processed % 100) == 0:\n",
    "        posts.to_csv(\"posts.csv\")\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    print(str(processed) + \" / \" + str(total) + \" processed, \" + str(percentage) + \"%\")\n",
    "    print(str(success) + \" successful\" + \" (\" + str((success/total)*100) + \"%)\")\n",
    "    print(str(failed) + \" failed\" + \" (\" + str((failed/total)*100) + \"%)\")\n",
    "    print(str(skipped) + \" skipped\" + \" (\" + str((skipped/total)*100) + \"%)\")\n",
    "    print(\"Index: \" + str(index))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8850 / 95620 processed, 9.25538590253085%\n",
      "7516 successful (7.860280276092868%)\n",
      "1329 failed (1.3898765948546328%)\n",
      "5 skipped (0.005229031583350764%)\n",
      "Exceptions: 5\n",
      "Index: 8849\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [69]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExceptions: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(exceptions))\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(index))\n\u001b[0;32m---> 93\u001b[0m \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (index \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m     95\u001b[0m     posts\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposts.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from os.path import exists\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "new_dir = \"pics\" # -\" + datetime.now().strftime(\"%m%d%Y%H%M%S\")\n",
    "final_directory = os.path.join(current_directory, new_dir)\n",
    "if not os.path.exists(final_directory):\n",
    "   os.makedirs(final_directory)\n",
    "\n",
    "processed = 0\n",
    "skipped = 0\n",
    "failed = 0\n",
    "success = 0\n",
    "status = \"\"\n",
    "exceptions = 0\n",
    "\n",
    "for index, row in posts.iterrows():\n",
    "    url =  row['URL']\n",
    "    filename = row['ID']\n",
    "    \n",
    "    if row['Status'] == \"Failed\":\n",
    "        failed += 1\n",
    "        processed += 1\n",
    "        status = \"skipped\"\n",
    "        continue\n",
    "        \n",
    "    if row['Status'] == \"BadURL\":\n",
    "        skipped += 1\n",
    "        processed += 1\n",
    "        status = \"skipped\"\n",
    "        continue\n",
    "        \n",
    "    if row['Status'] == \"Downloaded\":\n",
    "        success += 1\n",
    "        processed += 1\n",
    "        status = \"downloaded\"\n",
    "        continue\n",
    "        \n",
    "    if exists(final_directory + '/' + filename + '.jpg'):\n",
    "        success += 1\n",
    "        processed += 1\n",
    "        status = \"downloaded\"\n",
    "        continue\n",
    "        \n",
    "    matches = [\"://i.redd.it\", \"://i.imgur.com\"]\n",
    "    if not any(x in url for x in matches):\n",
    "        skipped += 1\n",
    "        processed += 1  \n",
    "        posts.at[index,'Status'] = \"BadURL\"\n",
    "        status = \"bad url\"\n",
    "        continue\n",
    "    try:\n",
    "        res = requests.get(url, stream = True, timeout=20)\n",
    "    except:\n",
    "        skipped += 1\n",
    "        processed += 1\n",
    "        exceptions += 1\n",
    "        posts.at[index,'Status'] = \"Exception\"\n",
    "        continue\n",
    "    if res.status_code == 200:\n",
    "        with open(final_directory + '/' + filename + '.jpg','wb') as f:\n",
    "            shutil.copyfileobj(res.raw, f)\n",
    "        success += 1\n",
    "        posts.at[index,'Status'] = \"Downloaded\"\n",
    "        status = \"downloaded\"\n",
    "        \n",
    "    else:\n",
    "        failed += 1\n",
    "        posts.at[index,'Status'] = \"Failed\"\n",
    "        status = \"failed\"\n",
    "        \n",
    "        \n",
    "    processed += 1\n",
    "    clear_output(wait=True)\n",
    "    total = 95620\n",
    "    percentage = (processed / total) * 100\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    # print(str(processed) + \" / \" + str(total) + \" processed, \" + str(percentage) + \"%\")\n",
    "    # print(str(success) + \" successful\" + \" (\" + str((success/total)*100) + \"%)\")\n",
    "    # print(str(failed) + \" failed\" + \" (\" + str((failed/total)*100) + \"%)\")\n",
    "    # print(str(skipped) + \" skipped\" + \" (\" + str((skipped/total)*100) + \"%)\")\n",
    "    # print(\"Exceptions: \" + str(exceptions))\n",
    "    # print(\"Index: \" + str(index))\n",
    "    \n",
    "    time.sleep(1)\n",
    "    if (index % 100 == 0):\n",
    "        posts.to_csv(\"posts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "posts.to_csv(\"posts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
